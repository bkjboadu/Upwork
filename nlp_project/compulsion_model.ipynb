{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import contractions\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#define the process of text cleaning\n",
    "def deEmojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r' ',text)\n",
    "\n",
    "#Clean Text\n",
    "def clean_text(data):\n",
    "    # convert catacter to lowercase\n",
    "    data['clean_text']=data['yy'].str.lower()\n",
    "    #remove URLS\n",
    "    data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r\"http\\S+\", \"\", elem))\n",
    "    #remove ponctuation\n",
    "    data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r\"[^\\w\\s]\", \"\", elem))\n",
    "    #remove\n",
    "    data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'/n',\"\",elem))\n",
    "    #remove degits\n",
    "    data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'\\d+',\"\",elem))\n",
    "    #remove emojis\n",
    "    data['clean_text'] = data['clean_text'].apply(lambda elem:deEmojify(elem))\n",
    "    #remove multiple spaces\n",
    "    data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'\\s+',\" \",elem))\n",
    "    #remove single caracter\n",
    "    data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'\\s+[a-zA-Z]\\s+',\" \",elem))\n",
    "    return data\n",
    "\n",
    "def process_text(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Handle contractions using the contractions library\n",
    "    expanded_text = contractions.fix(text)\n",
    "\n",
    "    # Lowercasing\n",
    "    expanded_text = expanded_text.lower()\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(expanded_text)\n",
    "\n",
    "    # Removing Punctuation\n",
    "    tokens = [word for word in tokens if word.isalnum()]\n",
    "\n",
    "    # Removing Stop Words\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>prefLabel</th>\n",
       "      <th>compulsion</th>\n",
       "      <th>obsession</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi -\\nSo I haven't been on here since December...</td>\n",
       "      <td>['depression', 'weight gain', 'Medication', 'a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi all, hope you're all having a wonderful ban...</td>\n",
       "      <td>['compulsion', 'anger', 'symptom', 'compassion...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi, \\nFirst, I hope everyone managed to have s...</td>\n",
       "      <td>['hope', 'happiness', 'guilt', 'fear', 'obsess...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello everyone. I could really use your help r...</td>\n",
       "      <td>['Treatment', 'hope', 'Thought', 'obsession', ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Though it comes in many flavors, one of the mo...</td>\n",
       "      <td>['quality', 'Intrusive thoughts', 'fall', 'beh...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8125</th>\n",
       "      <td>Good morning,\\nI have always found that my OCD...</td>\n",
       "      <td>['surprise', 'Intrusive thoughts', 'Thought', ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8126</th>\n",
       "      <td>The terror I felt when there were children pla...</td>\n",
       "      <td>['OCD', 'talking', 'Intrusive thoughts', 'Thou...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8127</th>\n",
       "      <td>Hi, I've started 2 have ocd when i was 10 whic...</td>\n",
       "      <td>['washing hands', 'object', 'fall', 'obsession...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8128</th>\n",
       "      <td>Hi Everyone,\\nA small true story that happened...</td>\n",
       "      <td>['Thought', 'drop', 'Rituals', 'OCD', 'compuls...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8129</th>\n",
       "      <td>Hey there, I'm having a very persistent intrus...</td>\n",
       "      <td>['compulsion', 'OCD', 'Thought']</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8130 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   post  \\\n",
       "0     Hi -\\nSo I haven't been on here since December...   \n",
       "1     Hi all, hope you're all having a wonderful ban...   \n",
       "2     Hi, \\nFirst, I hope everyone managed to have s...   \n",
       "3     Hello everyone. I could really use your help r...   \n",
       "4     Though it comes in many flavors, one of the mo...   \n",
       "...                                                 ...   \n",
       "8125  Good morning,\\nI have always found that my OCD...   \n",
       "8126  The terror I felt when there were children pla...   \n",
       "8127  Hi, I've started 2 have ocd when i was 10 whic...   \n",
       "8128  Hi Everyone,\\nA small true story that happened...   \n",
       "8129  Hey there, I'm having a very persistent intrus...   \n",
       "\n",
       "                                              prefLabel  compulsion  obsession  \n",
       "0     ['depression', 'weight gain', 'Medication', 'a...           0          1  \n",
       "1     ['compulsion', 'anger', 'symptom', 'compassion...           1          1  \n",
       "2     ['hope', 'happiness', 'guilt', 'fear', 'obsess...           0          1  \n",
       "3     ['Treatment', 'hope', 'Thought', 'obsession', ...           0          1  \n",
       "4     ['quality', 'Intrusive thoughts', 'fall', 'beh...           1          1  \n",
       "...                                                 ...         ...        ...  \n",
       "8125  ['surprise', 'Intrusive thoughts', 'Thought', ...           0          1  \n",
       "8126  ['OCD', 'talking', 'Intrusive thoughts', 'Thou...           0          1  \n",
       "8127  ['washing hands', 'object', 'fall', 'obsession...           0          1  \n",
       "8128  ['Thought', 'drop', 'Rituals', 'OCD', 'compuls...           1          0  \n",
       "8129                   ['compulsion', 'OCD', 'Thought']           1          0  \n",
       "\n",
       "[8130 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('post-ontology-label.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>prefLabel</th>\n",
       "      <th>compulsion</th>\n",
       "      <th>obsession</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi since december since recovering prozac sinc...</td>\n",
       "      <td>['depression', 'weight gain', 'Medication', 'a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi hope wonderful bank holiday whatever howeve...</td>\n",
       "      <td>['compulsion', 'anger', 'symptom', 'compassion...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hi first hope everyone managed joy happiness c...</td>\n",
       "      <td>['hope', 'happiness', 'guilt', 'fear', 'obsess...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hello everyone could really use help right ide...</td>\n",
       "      <td>['Treatment', 'hope', 'Thought', 'obsession', ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>though come many flavor one common ocd theme s...</td>\n",
       "      <td>['quality', 'Intrusive thoughts', 'fall', 'beh...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                post  \\\n",
       "0  hi since december since recovering prozac sinc...   \n",
       "1  hi hope wonderful bank holiday whatever howeve...   \n",
       "2  hi first hope everyone managed joy happiness c...   \n",
       "3  hello everyone could really use help right ide...   \n",
       "4  though come many flavor one common ocd theme s...   \n",
       "\n",
       "                                           prefLabel  compulsion  obsession  \n",
       "0  ['depression', 'weight gain', 'Medication', 'a...           0          1  \n",
       "1  ['compulsion', 'anger', 'symptom', 'compassion...           1          1  \n",
       "2  ['hope', 'happiness', 'guilt', 'fear', 'obsess...           0          1  \n",
       "3  ['Treatment', 'hope', 'Thought', 'obsession', ...           0          1  \n",
       "4  ['quality', 'Intrusive thoughts', 'fall', 'beh...           1          1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['post'] = df['post'].apply(process_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in training set: 6504\n",
      "Number of rows in validation set: 813\n",
      "Number of rows in test set: 813\n"
     ]
    }
   ],
   "source": [
    "test_split = 0.2\n",
    "\n",
    "# Initial train and test split.\n",
    "train_df, test_df = train_test_split(df, test_size=test_split, stratify=df[['compulsion']].values, )\n",
    "test_df,val_df = train_test_split(test_df,test_size=0.5,stratify=test_df[['compulsion']].values)\n",
    "# Splitting the test set further into validation and new test sets.\n",
    "# val_df = test_df.sample(frac=0.5)\n",
    "# test_df.drop(val_df.index, inplace=True)\n",
    "\n",
    "print(f\"Number of rows in training set: {len(train_df)}\")\n",
    "print(f\"Number of rows in validation set: {len(val_df)}\")\n",
    "print(f\"Number of rows in test set: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,train_y = train_df['post'], train_df[['compulsion']]\n",
    "test_x,test_y = test_df['post'], test_df[['compulsion']]\n",
    "val_x,val_y = val_df['post'], val_df[['compulsion']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMPULSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "  5/204 [..............................] - ETA: 2:06:13 - loss: 0.6823 - accuracy: 0.5813"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "# Load BERT tokenizer and model\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "compulsion_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Tokenize and encode the training and testing texts\n",
    "train_encodings = tokenizer(train_x.tolist(), truncation=True, padding=True, max_length=128, return_tensors='tf')\n",
    "test_encodings = tokenizer(test_x.tolist(), truncation=True, padding=True, max_length=128, return_tensors='tf')\n",
    "val_encodings = tokenizer(val_x.tolist(), truncation=True, padding=True, max_length=128, return_tensors='tf')\n",
    "\n",
    "# Convert labels to TensorFlow tensors\n",
    "train_labels = tf.convert_to_tensor(train_y, dtype=tf.int32)\n",
    "test_labels = tf.convert_to_tensor(test_y, dtype=tf.int32)\n",
    "val_labels = tf.convert_to_tensor(val_y, dtype=tf.int32)\n",
    "\n",
    "# Convert Hugging Face tokenized inputs to numpy arrays\n",
    "train_encodings = {key: np.array(value) for key, value in train_encodings.items()}\n",
    "test_encodings = {key: np.array(value) for key, value in test_encodings.items()}\n",
    "val_encodings = {key: np.array(value) for key, value in val_encodings.items()}\n",
    "# Compile the model\n",
    "compulsion_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = compulsion_model.fit(\n",
    "    train_encodings,\n",
    "    train_labels,\n",
    "    validation_data=(test_encodings, test_labels),\n",
    "    epochs=3,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = compulsion_model.predict(test_encodings)\n",
    "predicted_labels = tf.argmax(predictions.logits, axis=1)\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "classification_rep = classification_report(test_labels, predicted_labels)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compulsion_model.save_pretrained('hugging_face/compulsion_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_model = TFAutoModelForSequenceClassification.from_pretrained('hugging_face/compulsion_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAKING PREDICTION ON MANUAL_LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual = pd.read_csv('post-manual-label.csv')\n",
    "manual['post'] = manual['post'].apply(lambda x: process_text(str(x)))\n",
    "test_x = manual['post']\n",
    "test_encodings = tokenizer(test_x.tolist(), truncation=True, padding=True, max_length=128, return_tensors='tf')\n",
    "test_encodings = {key: np.array(value) for key, value in train_encodings.items()}\n",
    "\n",
    "test_y = compulsion_model.predict(test_encodings)\n",
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Computer-Vison Environment",
   "language": "python",
   "name": "cv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
