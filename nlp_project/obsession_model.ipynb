{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import contractions\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "from sklearn.metrics import classification_report, accuracy_score,confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#define the process of text cleaning\n",
    "def deEmojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r' ',text)\n",
    "\n",
    "#Clean Text\n",
    "def clean_text(data):\n",
    "    # convert catacter to lowercase\n",
    "    data['clean_text']=data['yy'].str.lower()\n",
    "    #remove URLS\n",
    "    data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r\"http\\S+\", \"\", elem))\n",
    "    #remove ponctuation\n",
    "    data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r\"[^\\w\\s]\", \"\", elem))\n",
    "    #remove\n",
    "    data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'/n',\"\",elem))\n",
    "    #remove degits\n",
    "    data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'\\d+',\"\",elem))\n",
    "    #remove emojis\n",
    "    data['clean_text'] = data['clean_text'].apply(lambda elem:deEmojify(elem))\n",
    "    #remove multiple spaces\n",
    "    data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'\\s+',\" \",elem))\n",
    "    #remove single caracter\n",
    "    data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'\\s+[a-zA-Z]\\s+',\" \",elem))\n",
    "    return data\n",
    "\n",
    "def process_text(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Handle contractions using the contractions library\n",
    "    expanded_text = contractions.fix(text)\n",
    "\n",
    "    # Lowercasing\n",
    "    expanded_text = expanded_text.lower()\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(expanded_text)\n",
    "\n",
    "    # Removing Punctuation\n",
    "    tokens = [word for word in tokens if word.isalnum()]\n",
    "\n",
    "    # Removing Stop Words\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>prefLabel</th>\n",
       "      <th>compulsion</th>\n",
       "      <th>obsession</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi -\\nSo I haven't been on here since December...</td>\n",
       "      <td>['depression', 'weight gain', 'Medication', 'a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi all, hope you're all having a wonderful ban...</td>\n",
       "      <td>['compulsion', 'anger', 'symptom', 'compassion...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi, \\nFirst, I hope everyone managed to have s...</td>\n",
       "      <td>['hope', 'happiness', 'guilt', 'fear', 'obsess...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello everyone. I could really use your help r...</td>\n",
       "      <td>['Treatment', 'hope', 'Thought', 'obsession', ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Though it comes in many flavors, one of the mo...</td>\n",
       "      <td>['quality', 'Intrusive thoughts', 'fall', 'beh...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8125</th>\n",
       "      <td>Good morning,\\nI have always found that my OCD...</td>\n",
       "      <td>['surprise', 'Intrusive thoughts', 'Thought', ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8126</th>\n",
       "      <td>The terror I felt when there were children pla...</td>\n",
       "      <td>['OCD', 'talking', 'Intrusive thoughts', 'Thou...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8127</th>\n",
       "      <td>Hi, I've started 2 have ocd when i was 10 whic...</td>\n",
       "      <td>['washing hands', 'object', 'fall', 'obsession...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8128</th>\n",
       "      <td>Hi Everyone,\\nA small true story that happened...</td>\n",
       "      <td>['Thought', 'drop', 'Rituals', 'OCD', 'compuls...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8129</th>\n",
       "      <td>Hey there, I'm having a very persistent intrus...</td>\n",
       "      <td>['compulsion', 'OCD', 'Thought']</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8130 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   post  \\\n",
       "0     Hi -\\nSo I haven't been on here since December...   \n",
       "1     Hi all, hope you're all having a wonderful ban...   \n",
       "2     Hi, \\nFirst, I hope everyone managed to have s...   \n",
       "3     Hello everyone. I could really use your help r...   \n",
       "4     Though it comes in many flavors, one of the mo...   \n",
       "...                                                 ...   \n",
       "8125  Good morning,\\nI have always found that my OCD...   \n",
       "8126  The terror I felt when there were children pla...   \n",
       "8127  Hi, I've started 2 have ocd when i was 10 whic...   \n",
       "8128  Hi Everyone,\\nA small true story that happened...   \n",
       "8129  Hey there, I'm having a very persistent intrus...   \n",
       "\n",
       "                                              prefLabel  compulsion  obsession  \n",
       "0     ['depression', 'weight gain', 'Medication', 'a...           0          1  \n",
       "1     ['compulsion', 'anger', 'symptom', 'compassion...           1          1  \n",
       "2     ['hope', 'happiness', 'guilt', 'fear', 'obsess...           0          1  \n",
       "3     ['Treatment', 'hope', 'Thought', 'obsession', ...           0          1  \n",
       "4     ['quality', 'Intrusive thoughts', 'fall', 'beh...           1          1  \n",
       "...                                                 ...         ...        ...  \n",
       "8125  ['surprise', 'Intrusive thoughts', 'Thought', ...           0          1  \n",
       "8126  ['OCD', 'talking', 'Intrusive thoughts', 'Thou...           0          1  \n",
       "8127  ['washing hands', 'object', 'fall', 'obsession...           0          1  \n",
       "8128  ['Thought', 'drop', 'Rituals', 'OCD', 'compuls...           1          0  \n",
       "8129                   ['compulsion', 'OCD', 'Thought']           1          0  \n",
       "\n",
       "[8130 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('post-ontology-label.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>prefLabel</th>\n",
       "      <th>compulsion</th>\n",
       "      <th>obsession</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi since december since recovering prozac sinc...</td>\n",
       "      <td>['depression', 'weight gain', 'Medication', 'a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi hope wonderful bank holiday whatever howeve...</td>\n",
       "      <td>['compulsion', 'anger', 'symptom', 'compassion...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hi first hope everyone managed joy happiness c...</td>\n",
       "      <td>['hope', 'happiness', 'guilt', 'fear', 'obsess...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hello everyone could really use help right ide...</td>\n",
       "      <td>['Treatment', 'hope', 'Thought', 'obsession', ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>though come many flavor one common ocd theme s...</td>\n",
       "      <td>['quality', 'Intrusive thoughts', 'fall', 'beh...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                post  \\\n",
       "0  hi since december since recovering prozac sinc...   \n",
       "1  hi hope wonderful bank holiday whatever howeve...   \n",
       "2  hi first hope everyone managed joy happiness c...   \n",
       "3  hello everyone could really use help right ide...   \n",
       "4  though come many flavor one common ocd theme s...   \n",
       "\n",
       "                                           prefLabel  compulsion  obsession  \n",
       "0  ['depression', 'weight gain', 'Medication', 'a...           0          1  \n",
       "1  ['compulsion', 'anger', 'symptom', 'compassion...           1          1  \n",
       "2  ['hope', 'happiness', 'guilt', 'fear', 'obsess...           0          1  \n",
       "3  ['Treatment', 'hope', 'Thought', 'obsession', ...           0          1  \n",
       "4  ['quality', 'Intrusive thoughts', 'fall', 'beh...           1          1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['post'] = df['post'].apply(process_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in training set: 6504\n",
      "Number of rows in validation set: 813\n",
      "Number of rows in test set: 813\n"
     ]
    }
   ],
   "source": [
    "test_split = 0.2\n",
    "\n",
    "# Initial train and test split.\n",
    "train_df, test_df = train_test_split(df, test_size=test_split, stratify=df[['obsession']].values, )\n",
    "test_df,val_df = train_test_split(test_df,test_size=0.5,stratify=test_df[['obsession']].values)\n",
    "# Splitting the test set further into validation and new test sets.\n",
    "# val_df = test_df.sample(frac=0.5)\n",
    "# test_df.drop(val_df.index, inplace=True)\n",
    "\n",
    "print(f\"Number of rows in training set: {len(train_df)}\")\n",
    "print(f\"Number of rows in validation set: {len(val_df)}\")\n",
    "print(f\"Number of rows in test set: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,train_y = train_df['post'], train_df[['obsession']]\n",
    "test_x,test_y = test_df['post'], test_df[['obsession']]\n",
    "val_x,val_y = val_df['post'], val_df[['obsession']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OBSESSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "204/204 [==============================] - 7003s 34s/step - loss: 0.3916 - accuracy: 0.8318 - val_loss: 0.1125 - val_accuracy: 0.9533\n",
      "Epoch 2/3\n",
      "204/204 [==============================] - 7295s 36s/step - loss: 0.1297 - accuracy: 0.9502 - val_loss: 0.0869 - val_accuracy: 0.9619\n",
      "Epoch 3/3\n",
      "156/204 [=====================>........] - ETA: 54:34 - loss: 0.0959 - accuracy: 0.9641"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\bkj\\Documents\\GitHub\\projects\\Upwork\\nlp_project\\obsession_model.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bkj/Documents/GitHub/projects/Upwork/nlp_project/obsession_model.ipynb#X10sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# Compile the model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bkj/Documents/GitHub/projects/Upwork/nlp_project/obsession_model.ipynb#X10sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m obsession_model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m1e-5\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bkj/Documents/GitHub/projects/Upwork/nlp_project/obsession_model.ipynb#X10sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m               loss\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bkj/Documents/GitHub/projects/Upwork/nlp_project/obsession_model.ipynb#X10sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m               metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/bkj/Documents/GitHub/projects/Upwork/nlp_project/obsession_model.ipynb#X10sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m history \u001b[39m=\u001b[39m obsession_model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bkj/Documents/GitHub/projects/Upwork/nlp_project/obsession_model.ipynb#X10sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     train_encodings,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bkj/Documents/GitHub/projects/Upwork/nlp_project/obsession_model.ipynb#X10sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     train_labels,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bkj/Documents/GitHub/projects/Upwork/nlp_project/obsession_model.ipynb#X10sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(test_encodings, test_labels),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bkj/Documents/GitHub/projects/Upwork/nlp_project/obsession_model.ipynb#X10sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bkj/Documents/GitHub/projects/Upwork/nlp_project/obsession_model.ipynb#X10sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bkj/Documents/GitHub/projects/Upwork/nlp_project/obsession_model.ipynb#X10sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bkj/Documents/GitHub/projects/Upwork/nlp_project/obsession_model.ipynb#X10sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bkj/Documents/GitHub/projects/Upwork/nlp_project/obsession_model.ipynb#X10sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m predictions \u001b[39m=\u001b[39m obsession_model\u001b[39m.\u001b[39mpredict(test_encodings)\n",
      "File \u001b[1;32mc:\\Users\\bkj\\Documents\\GitHub\\projects\\computer vision\\cv-env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\bkj\\Documents\\GitHub\\projects\\computer vision\\cv-env\\Lib\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\bkj\\Documents\\GitHub\\projects\\computer vision\\cv-env\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\bkj\\Documents\\GitHub\\projects\\computer vision\\cv-env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\bkj\\Documents\\GitHub\\projects\\computer vision\\cv-env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[0;32m    869\u001b[0m   )\n\u001b[0;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\bkj\\Documents\\GitHub\\projects\\computer vision\\cv-env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\bkj\\Documents\\GitHub\\projects\\computer vision\\cv-env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\bkj\\Documents\\GitHub\\projects\\computer vision\\cv-env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\bkj\\Documents\\GitHub\\projects\\computer vision\\cv-env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\bkj\\Documents\\GitHub\\projects\\computer vision\\cv-env\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1485\u001b[0m   )\n\u001b[0;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\bkj\\Documents\\GitHub\\projects\\computer vision\\cv-env\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "# Load BERT tokenizer and model\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "obsession_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Tokenize and encode the training and testing texts\n",
    "train_encodings = tokenizer(train_x.tolist(), truncation=True, padding=True, max_length=128, return_tensors='tf')\n",
    "test_encodings = tokenizer(test_x.tolist(), truncation=True, padding=True, max_length=128, return_tensors='tf')\n",
    "val_encodings = tokenizer(val_x.tolist(), truncation=True, padding=True, max_length=128, return_tensors='tf')\n",
    "\n",
    "# Convert labels to TensorFlow tensors\n",
    "train_labels = tf.convert_to_tensor(train_y, dtype=tf.int32)\n",
    "test_labels = tf.convert_to_tensor(test_y, dtype=tf.int32)\n",
    "val_labels = tf.convert_to_tensor(val_y, dtype=tf.int32)\n",
    "\n",
    "# Convert Hugging Face tokenized inputs to numpy arrays\n",
    "train_encodings = {key: np.array(value) for key, value in train_encodings.items()}\n",
    "test_encodings = {key: np.array(value) for key, value in test_encodings.items()}\n",
    "val_encodings = {key: np.array(value) for key, value in val_encodings.items()}\n",
    "# Compile the model\n",
    "obsession_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = obsession_model.fit(\n",
    "    train_encodings,\n",
    "    train_labels,\n",
    "    validation_data=(test_encodings, test_labels),\n",
    "    epochs=3,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = obsession_model.predict(test_encodings)\n",
    "predicted_labels = tf.argmax(predictions.logits, axis=1)\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "classification_rep = classification_report(test_labels, predicted_labels)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsession_model.save_pretrained('hugging_face/obsession_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at hugging_face/all_model were not used when initializing TFBertForSequenceClassification: ['dropout_493']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at hugging_face/all_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "loaded_model = TFAutoModelForSequenceClassification.from_pretrained('hugging_face/all_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAKING PREDICTION ON MANUAL_LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>prefLabel</th>\n",
       "      <th>obsession_first_checker</th>\n",
       "      <th>compulsion_first_checker</th>\n",
       "      <th>expand1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grew obsessive thought aptly intrusive thought...</td>\n",
       "      <td>['site', 'compulsion', 'obsession', 'rash', 'p...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Aggressive obsession, Contamination obsession,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thinking much covid part job well right concer...</td>\n",
       "      <td>['singing', 'washing hands', 'anxiety', 'anxie...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>morbid thoughts, Mental image, Homicidal thoug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fed send day checking excessive checking every...</td>\n",
       "      <td>['OCD', 'checking', 'Thought']</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>morbid thoughts, Mental image, Homicidal thoug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>noticed washing hand lately thing triggering n...</td>\n",
       "      <td>['washing hands', 'hope', 'depression', 'OCD']</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sound stupid moment want download window live ...</td>\n",
       "      <td>['Thought']</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>morbid thoughts, Mental image, Homicidal thoug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>http http buddhist podcast chanting beginning ...</td>\n",
       "      <td>['interest', 'Thought', 'OCD', 'cognitive proc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>morbid thoughts, Mental image, Homicidal thoug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>hi lot helpful topic forum previous discussion...</td>\n",
       "      <td>['OCD']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>aww guy sorry feel always mithering everyone i...</td>\n",
       "      <td>['OCD', 'sadness', 'weakness', 'anxiety', 'anx...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>castration anxiety, performance anxiety, koro,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>name ian suffered ocd life become problem last...</td>\n",
       "      <td>['OCD', 'hope', 'fear']</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>terror, panic, panic, moral panic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>posted another thread thought might helpful ot...</td>\n",
       "      <td>['Thought', 'email', 'hope', 'OCD']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>morbid thoughts, Mental image, Homicidal thoug...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>496 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  post  \\\n",
       "0    grew obsessive thought aptly intrusive thought...   \n",
       "1    thinking much covid part job well right concer...   \n",
       "2    fed send day checking excessive checking every...   \n",
       "3    noticed washing hand lately thing triggering n...   \n",
       "4    sound stupid moment want download window live ...   \n",
       "..                                                 ...   \n",
       "491  http http buddhist podcast chanting beginning ...   \n",
       "492  hi lot helpful topic forum previous discussion...   \n",
       "493  aww guy sorry feel always mithering everyone i...   \n",
       "494  name ian suffered ocd life become problem last...   \n",
       "495  posted another thread thought might helpful ot...   \n",
       "\n",
       "                                             prefLabel  \\\n",
       "0    ['site', 'compulsion', 'obsession', 'rash', 'p...   \n",
       "1    ['singing', 'washing hands', 'anxiety', 'anxie...   \n",
       "2                       ['OCD', 'checking', 'Thought']   \n",
       "3       ['washing hands', 'hope', 'depression', 'OCD']   \n",
       "4                                          ['Thought']   \n",
       "..                                                 ...   \n",
       "491  ['interest', 'Thought', 'OCD', 'cognitive proc...   \n",
       "492                                            ['OCD']   \n",
       "493  ['OCD', 'sadness', 'weakness', 'anxiety', 'anx...   \n",
       "494                            ['OCD', 'hope', 'fear']   \n",
       "495                ['Thought', 'email', 'hope', 'OCD']   \n",
       "\n",
       "     obsession_first_checker  compulsion_first_checker  \\\n",
       "0                          1                         1   \n",
       "1                          0                         1   \n",
       "2                          0                         1   \n",
       "3                          1                         0   \n",
       "4                          1                         1   \n",
       "..                       ...                       ...   \n",
       "491                        0                         0   \n",
       "492                        0                         0   \n",
       "493                        0                         0   \n",
       "494                        1                         0   \n",
       "495                        0                         0   \n",
       "\n",
       "                                               expand1  \n",
       "0    Aggressive obsession, Contamination obsession,...  \n",
       "1    morbid thoughts, Mental image, Homicidal thoug...  \n",
       "2    morbid thoughts, Mental image, Homicidal thoug...  \n",
       "3                                                  NaN  \n",
       "4    morbid thoughts, Mental image, Homicidal thoug...  \n",
       "..                                                 ...  \n",
       "491  morbid thoughts, Mental image, Homicidal thoug...  \n",
       "492                                                NaN  \n",
       "493  castration anxiety, performance anxiety, koro,...  \n",
       "494                  terror, panic, panic, moral panic  \n",
       "495  morbid thoughts, Mental image, Homicidal thoug...  \n",
       "\n",
       "[496 rows x 5 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_excel('test_data.xlsx')\n",
    "test_data['post'] = test_data['post'].apply(lambda x: process_text(str(x)))\n",
    "test_x = test_data['post']\n",
    "test_y = test_data['obsession_first_checker']\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(test_x) == len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 232s 14s/step\n"
     ]
    }
   ],
   "source": [
    "test_encodings = tokenizer(test_x.tolist(), truncation=True, padding=True, max_length=128, return_tensors='tf')\n",
    "test_encodings = {key: np.array(value) for key, value in test_encodings.items()}\n",
    "\n",
    "y_pred = obsession_model.predict(test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.argmax(y_pred.logits, axis=1)\n",
    "accuracy = accuracy_score(test_y, y_pred)\n",
    "classification_rep = classification_report(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45161290322580644"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.66      0.31      0.42       319\\n           1       0.36      0.71      0.48       177\\n\\n    accuracy                           0.45       496\\n   macro avg       0.51      0.51      0.45       496\\nweighted avg       0.55      0.45      0.44       496\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      0\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "491    0\n",
       "492    0\n",
       "493    0\n",
       "494    1\n",
       "495    0\n",
       "Name: obsession_first_checker, Length: 496, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "compulsion_model = TFAutoModelForSequenceClassification.from_pretrained('hugging_face/all_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 98, 221],\n",
       "       [ 51, 126]], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_metrics = confusion_matrix(test_y,y_pred)\n",
    "confusion_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Computer-Vison Environment",
   "language": "python",
   "name": "cv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
